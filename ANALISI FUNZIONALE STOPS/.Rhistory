lines(media+pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=3)
lines(media-pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC2")
x11()
plot(pca_W.1$scores[,1],pca_W.1$scores[,2],type="n",xlab="Scores FPC1",
ylab="Scores FPC2")
text(pca_W.1$scores[,1],pca_W.1$scores[,2], cex=1)
par(mfrow=c(1,3))
plot.pca.fd(pca_W.1, nx=100, pointplot=TRUE, harm=c(1,2,3), expand=0, cycle=FALSE)
x11()
par(mfrow=c(1,3))
plot.pca.fd(pca_W.1, nx=100, pointplot=TRUE, harm=c(1,2,3), expand=0, cycle=FALSE)
x11()
media <- mean.fd(data_W.fd.1)
par(mfrow=c(3,1))
plot(media,lwd=2,ylim=c(-25,31),ylab='Stops by each hour ~ 08/06 - 14/06',main='FPC1')
lines(media+pca_W.1$harmonics[1,]*sqrt(pca_W.1$values[1]), col=3)
lines(media-pca_W.1$harmonics[1,]*sqrt(pca_W.1$values[1]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC1 - 70.1% of variability")
plot(media,lwd=2,ylim=c(-2,17),ylab='Stops by each hour ~ 08/06 - 14/06',main='FPC2')
lines(media+pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=3)
lines(media-pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC2 - 13% of variability")
plot(media,lwd=2,ylim=c(-2,17),ylab='Stops by each hour ~ 08/06 - 14/06',main='FPC3')
lines(media+pca_W.1$harmonics[3,]*sqrt(pca_W.1$values[3]), col=3)
lines(media-pca_W.1$harmonics[3,]*sqrt(pca_W.1$values[3]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC3 - 4% of variability")
# fra
load("C:/Users/franc/Desktop/PoliMI/Anno Accademico 2020-2021/Applied Statistics/Progetto/Applied-statistics-project/DATASET/NYC_no_river.RData")
load("C:/Users/franc/Desktop/PoliMI/Anno Accademico 2020-2021/Applied Statistics/Progetto/Applied-statistics-project/DATASET/CBG_NY_no_river.RData")
New_York_County_no_river= New_York_County_no_river[order( New_York_County_no_river$area),]
CBG_ny_no_river<-CBG_ny_no_river[order( CBG_ny_no_river$CensusBlockGroup),]
attach( New_York_County_no_river)
stops<-matrix(nrow = 1092, ncol=30*24)
for (i in 1:dim( New_York_County_no_river)[1]) {
stops[i,]<-stops_by_each_hour[[i]]
}
detach( New_York_County_no_river)
stops<-stops[,504:671]
stops<-t(stops)
colnames(stops)<- New_York_County_no_river$area
x11()
matplot(stops,type='l', main = "22/06 - 28/06")
x11()
matplot(stops,type='l', main = "22/06 - 28/06")
abline(v=seq(1,168, by=24), lty=2)
nbasis <- 28 # number of basis
# Create the basis
#FOURIER
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
x11()
plot.fd(data_W.fd.1)
abline(v=seq(1,168, by=24), lty=2)
title("22/06 - 28/06 (smoothing)")
arm=5 #numero armoniche
plot.fd(data_W.fd.1)
pca_W.1 <- pca.fd(data_W.fd.1,nharm=arm,centerfns=TRUE) #build a functional object before run it -> smoothing preprocessing
# scree plot
# pca.fd computes all the 365 eigenvalues, but only the first are non null
plot(pca_W.1$values[1:5],xlab='j',ylab='Eigenvalues')
plot(cumsum(pca_W.1$values)[1:5]/sum(pca_W.1$values),xlab='j',ylab='CPV',ylim=c(0.8,1))
layout(cbind(1,2,3))
plot(pca_W.1$harmonics[1,],col=1,ylab='FPC1')
abline(h=0,lty=2)
plot(pca_W.1$harmonics[2,],col=2,ylab='FPC2')
plot(pca_W.1$harmonics[3,],col=2,ylab='FPC3')
par(mfrow=c(1,3))
plot.pca.fd(pca_W.1, nx=100, pointplot=TRUE, harm=c(1,2,3), expand=0, cycle=FALSE)
x11()
plot(pca_W.1$scores[,1],pca_W.1$scores[,2],type="n",xlab="Scores FPC1",
ylab="Scores FPC2")
text(pca_W.1$scores[,1],pca_W.1$scores[,2], cex=1)
x11()
plot(pca_W.1$scores[,1],pca_W.1$scores[,2],type="n",xlab="Scores FPC1",
ylab="Scores FPC2")
text(pca_W.1$scores[,1],pca_W.1$scores[,2], cex=1)
out=c(92,532)
cbg_out=New_York_County_no_river[out,1]
layout(1)
x11()
matplot(stops,type='l')
lines(stops[,92],lwd=4, col=2)
lines(stops[,532],lwd=4, col=1)
# togliamo questi outliers
stops<-stops[,-out]
x11()
matplot(stops,type='l',main = "22/06 - 28/06")
abline(v=seq(1,168, by=24), lty=2)
abscissa<-1:168
Xobs0<-stops
nbasis <- 80 # number of basis
# Create the basis
#FOURIER
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
x11()
plot.fd(data_W.fd.1)
title("08/06 - 14/06 (smoothing)")
x11()
plot.fd(data_W.fd.1)
title("08/06 - 14/06 (smoothing)")
abline(v=seq(1,168, by=24), lty=2)
arm=5 #numero armoniche
plot.fd(data_W.fd.1)
pca_W.1 <- pca.fd(data_W.fd.1,nharm=arm,centerfns=TRUE) #build a functional object before run it -> smoothing preprocessing
# scree plot
# pca.fd computes all the 365 eigenvalues, but only the first are non null
plot(pca_W.1$values[1:5],xlab='j',ylab='Eigenvalues')
plot(cumsum(pca_W.1$values)[1:5]/sum(pca_W.1$values),xlab='j',ylab='CPV',ylim=c(0.8,1))
layout(cbind(1,2,3))
plot(pca_W.1$harmonics[1,],col=1,ylab='FPC1')
abline(h=0,lty=2)
plot(pca_W.1$harmonics[2,],col=2,ylab='FPC2')
plot(pca_W.1$harmonics[3,],col=2,ylab='FPC3')
par(mfrow=c(1,3))
plot.pca.fd(pca_W.1, nx=100, pointplot=TRUE, harm=c(1,2,3), expand=0, cycle=FALSE)
x11()
par(mfrow=c(1,3))
plot.pca.fd(pca_W.1, nx=100, pointplot=TRUE, harm=c(1,2,3), expand=0, cycle=FALSE)
x11()
media <- mean.fd(data_W.fd.1)
par(mfrow=c(3,1))
plot(media,lwd=2,ylim=c(-25,31),ylab='Stops by each our ~ 22/06 - 28/06',main='FPC1')
lines(media+pca_W.1$harmonics[1,]*sqrt(pca_W.1$values[1]), col=3)
lines(media-pca_W.1$harmonics[1,]*sqrt(pca_W.1$values[1]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC1 - 72.5% of variability")
plot(media,lwd=2,ylim=c(-2,17),ylab='Stops by each our ~ 22/06 - 28/06',main='FPC2')
lines(media+pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=3)
lines(media-pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC2 - 11.8% of variability")
plot(media,lwd=2,ylim=c(-2,17),ylab='Stops by each our ~ 22/06 - 28/06',main='FPC2')
lines(media+pca_W.1$harmonics[3,]*sqrt(pca_W.1$values[3]), col=3)
lines(media-pca_W.1$harmonics[3,]*sqrt(pca_W.1$values[3]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC2 - 4.8% of variability")
x11()
plot(pca_W.1$scores[,1],pca_W.1$scores[,2],type="n",xlab="Scores FPC1",
ylab="Scores FPC2")
text(pca_W.1$scores[,1],pca_W.1$scores[,2], cex=1)
# Evaluate the basis on the grid of abscissa
abscissa<-time
basismat <- eval.basis(abscissa, basis) #
dim(basismat)
head(basismat)
Xobs0<-stops
Xsp <- smooth.basis(argvals=abscissa, y=Xobs0, fdParobj=basis) # easier because it includes also penalization (see later)
Xsp0 <- eval.fd(abscissa, Xsp$fd) #  the curve smoothing the data
Xsp1 <- eval.fd(abscissa, Xsp$fd, Lfd=1) # first derivative
x11()
matplot(Xsp1, type ="l")
sigma <- 0.003 # True sigma. Estimated before as sigmahat
nbasis <- 9:100 # possible number of basis
integrationinterval <- 1:168
bias <- rep(NA,len=length(nbasis))
var <- rep(NA,len=length(nbasis))
for (j in 1:length(nbasis)){
basis <- create.bspline.basis(c(0,1), nbasis[j], m)
basismat <- eval.basis(abscissa, basis)
S <- basismat%*%solve(t(basismat)%*%basismat)%*%t(basismat)
bias[j] <- sum((truecurve$X0vera-S%*%truecurve$X0vera)[integrationinterval])
var[j] <- (sigma^2)*sum(diag(S[integrationinterval,integrationinterval]))
}
bias <- rep(NA,len=length(nbasis))
var <- rep(NA,len=length(nbasis))
for (j in 1:length(nbasis)){
basis <-  create.fourier.basis(rangeval=c(1,168),nbasis=nbasis[j])
basismat <- eval.basis(abscissa, basis)
S <- basismat%*%solve(t(basismat)%*%basismat)%*%t(basismat)
bias[j] <- sum((truecurve$X0vera-S%*%truecurve$X0vera)[integrationinterval])
var[j] <- (sigma^2)*sum(diag(S[integrationinterval,integrationinterval]))
}
mse <- var+bias^2
sigma <- 0.003 # True sigma. Estimated before as sigmahat
nbasis <- 9:100 # possible number of basis
integrationinterval <- 1:168
bias <- rep(NA,len=length(nbasis))
var <- rep(NA,len=length(nbasis))
for (j in 1:length(nbasis)){
basis <-  create.fourier.basis(rangeval=c(1,168),nbasis=nbasis[j])
basismat <- eval.basis(abscissa, basis)
S <- basismat%*%solve(t(basismat)%*%basismat)%*%t(basismat)
bias[j] <- sum((stops-S%*%stops)[integrationinterval])
var[j] <- (sigma^2)*sum(diag(S[integrationinterval,integrationinterval]))
}
mse <- var+bias^2
par(mfrow=c(1,1))
plot(nbasis,bias^2,ylim=c(0,max(mse)),type="l",ylab="",main="Bias-Variance tradeoff")
points(nbasis,var,col="red",type="l")
points(nbasis,mse,col="green",type="l",lwd=3)
legend('topright', c("Bias","Var","MSE"), col=c("black","red","green"),
lty=1, cex=.5)
var
x11()
par(mfrow=c(1,1))
plot(nbasis,bias^2,type="l",ylab="",main="Bias-Variance tradeoff")
points(nbasis,var,col="red",type="l")
points(nbasis,mse,col="green",type="l",lwd=3)
legend('topright', c("Bias","Var","MSE"), col=c("black","red","green"),
lty=1, cex=.5)
plot(nbasis,bias^2,type="l",ylab="",main="Bias-Variance tradeoff")
x11()
plot(nbasis,bias^2,type="l",ylab="",main="Bias-Variance tradeoff")
points(nbasis,var,col="red",type="l")
x11()
plot(nbasis,var,col="red",type="l")
breaks <- abscissa[((0:50)*2)+1]
breaks
# Create the basis
help(create.bspline.basis)
breaks <- abscissa[((0:84)*2)+1]
breaks
breaks <- abscissa[1,((1:84)*2)]
breaks <- abscissa[c(1,(1:84)*2)]
breaks
basis <- create.fourier.basis(breaks,nbasis=nbasis) # creates a fourier basis
help(create.fourier.basis)
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
# fra
load("C:/Users/franc/Desktop/PoliMI/Anno Accademico 2020-2021/Applied Statistics/Progetto/Applied-statistics-project/DATASET/NYC_no_river.RData")
load("C:/Users/franc/Desktop/PoliMI/Anno Accademico 2020-2021/Applied Statistics/Progetto/Applied-statistics-project/DATASET/CBG_NY_no_river.RData")
#--------------------------------------------------------------------
# Build dataset
New_York_County_no_river= New_York_County_no_river[order( New_York_County_no_river$area),]
CBG_ny_no_river<-CBG_ny_no_river[order( CBG_ny_no_river$CensusBlockGroup),]
attach( New_York_County_no_river)
stops<-matrix(nrow = 1092, ncol=30*24)
for (i in 1:dim( New_York_County_no_river)[1]) {
stops[i,]<-stops_by_each_hour[[i]]
}
detach( New_York_County_no_river)
stops<-stops[,504:671]
stops<-t(stops)
colnames(stops)<- New_York_County_no_river$area
x11()
matplot(stops,type='l', main = "22/06 - 28/06")
abline(v=seq(1,168, by=24), lty=2)
nbasis <- 28 # number of basis
# Create the basis
#FOURIER
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
x11()
plot.fd(data_W.fd.1)
abline(v=seq(1,168, by=24), lty=2)
title("22/06 - 28/06 (smoothing)")
# FPCA
arm=5 #numero armoniche
plot.fd(data_W.fd.1)
pca_W.1 <- pca.fd(data_W.fd.1,nharm=arm,centerfns=TRUE) #build a functional object before run it -> smoothing preprocessing
# scree plot
# pca.fd computes all the 365 eigenvalues, but only the first are non null
plot(pca_W.1$values[1:5],xlab='j',ylab='Eigenvalues')
plot(cumsum(pca_W.1$values)[1:5]/sum(pca_W.1$values),xlab='j',ylab='CPV',ylim=c(0.8,1))
layout(cbind(1,2,3))
plot(pca_W.1$harmonics[1,],col=1,ylab='FPC1')
abline(h=0,lty=2)
plot(pca_W.1$harmonics[2,],col=2,ylab='FPC2')
plot(pca_W.1$harmonics[3,],col=2,ylab='FPC3')
par(mfrow=c(1,3))
plot.pca.fd(pca_W.1, nx=100, pointplot=TRUE, harm=c(1,2,3), expand=0, cycle=FALSE)
x11()
par(mfrow=c(1,2))
media <- mean.fd(data_W.fd.1)
plot(media,lwd=2,ylim=c(-15,33),ylab='Stops by each hour',main='FPC1')
lines(media+pca_W.1$harmonics[1,]*sqrt(pca_W.1$values[1]), col=2)
lines(media-pca_W.1$harmonics[1,]*sqrt(pca_W.1$values[1]), col=3)
abline(v=seq(1,168, by=24), lty=2)
title('FPC1')
plot(media,lwd=2,ylim=c(-2,20),lab='Stops by each hour',main='FPC2')
lines(media+pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=2)
lines(media-pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=3)
abline(v=seq(1,168, by=24), lty=2)
title('FPC2')
# PC2 -> contrasto tra weekend e weekday
# PC1 -> media
# scatter plot of the scores
par(mfrow=c(1,2))
plot(pca_W.1$scores[,1],pca_W.1$scores[,2],xlab="Scores FPC1",ylab="Scores FPC2",lwd=2)
plot(pca_W.1$scores[,1],pca_W.1$scores[,2],type="n",xlab="Scores FPC1",
ylab="Scores FPC2")
text(pca_W.1$scores[,1],pca_W.1$scores[,2], labels=New_York_County_no_river$area, cex=1)
x11()
plot(pca_W.1$scores[,1],pca_W.1$scores[,2],type="n",xlab="Scores FPC1",
ylab="Scores FPC2")
text(pca_W.1$scores[,1],pca_W.1$scores[,2], cex=1)
# outliers
out=c(92,532)
cbg_out=New_York_County_no_river[out,1]
layout(1)
x11()
matplot(stops,type='l')
lines(stops[,92],lwd=4, col=2)
lines(stops[,532],lwd=4, col=1)
# togliamo questi outliers
stops<-stops[,-out]
x11()
matplot(stops,type='l',main = "22/06 - 28/06")
abline(v=seq(1,168, by=24), lty=2)
abscissa<-1:168
Xobs0<-stops
nbasis <- 80 # number of basis
# Create the basis
#FOURIER
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
x11()
plot.fd(data_W.fd.1)
title("08/06 - 14/06 (smoothing)")
abline(v=seq(1,168, by=24), lty=2)
# FPCA
arm=5 #numero armoniche
plot.fd(data_W.fd.1)
pca_W.1 <- pca.fd(data_W.fd.1,nharm=arm,centerfns=TRUE) #build a functional object before run it -> smoothing preprocessing
# scree plot
# pca.fd computes all the 365 eigenvalues, but only the first are non null
plot(pca_W.1$values[1:5],xlab='j',ylab='Eigenvalues')
plot(cumsum(pca_W.1$values)[1:5]/sum(pca_W.1$values),xlab='j',ylab='CPV',ylim=c(0.8,1))
layout(cbind(1,2,3))
plot(pca_W.1$harmonics[1,],col=1,ylab='FPC1')
abline(h=0,lty=2)
plot(pca_W.1$harmonics[2,],col=2,ylab='FPC2')
plot(pca_W.1$harmonics[3,],col=2,ylab='FPC3')
x11()
media <- mean.fd(data_W.fd.1)
par(mfrow=c(3,1))
plot(media,lwd=2,ylim=c(-25,31),ylab='Stops by each our ~ 22/06 - 28/06',main='FPC1')
lines(media+pca_W.1$harmonics[1,]*sqrt(pca_W.1$values[1]), col=3)
lines(media-pca_W.1$harmonics[1,]*sqrt(pca_W.1$values[1]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC1 - 72.5% of variability")
plot(media,lwd=2,ylim=c(-2,17),ylab='Stops by each our ~ 22/06 - 28/06',main='FPC2')
lines(media+pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=3)
lines(media-pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC2 - 11.8% of variability")
plot(media,lwd=2,ylim=c(-2,17),ylab='Stops by each our ~ 22/06 - 28/06',main='FPC2')
lines(media+pca_W.1$harmonics[3,]*sqrt(pca_W.1$values[3]), col=3)
lines(media-pca_W.1$harmonics[3,]*sqrt(pca_W.1$values[3]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC2 - 4.8% of variability")
x11()
par(mfrow=c(1,3))
plot.pca.fd(pca_W.1, nx=100, pointplot=TRUE, harm=c(1,2,3), expand=0, cycle=FALSE)
# scatter plot of the scores
par(mfrow=c(1,2))
plot(pca_W.1$scores[,1],pca_W.1$scores[,2],xlab="Scores FPC1",ylab="Scores FPC2",lwd=2)
plot(pca_W.1$scores[,1],pca_W.1$scores[,2],type="n",xlab="Scores FPC1",
ylab="Scores FPC2")
text(pca_W.1$scores[,1],pca_W.1$scores[,2], labels=New_York_County_no_river$area, cex=1)
x11()
plot(pca_W.1$scores[,1],pca_W.1$scores[,2],type="n",xlab="Scores FPC1",
ylab="Scores FPC2")
text(pca_W.1$scores[,1],pca_W.1$scores[,2], cex=1)
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
functionalPar <- fdPar(fdobj=basis, Lfdobj=3, lambda=1e-8)  # penalization term of the 3rd derivative
Xss <- smooth.basis(abscissa, Xobs0, functionalPar) # estimate we obtain
Xss0 <- eval.fd(abscissa, Xss$fd, Lfd=0)
Xss1 <- eval.fd(abscissa, Xss$fd, Lfd=1)
Xss2 <- eval.fd(abscissa, Xss$fd, Lfd=2)
df <- Xss$df   #  the degrees of freedom in the smoothing curve (17 dof -> linear operator but not a projection (in linear models is the trace of the projector operator))
df # it may be not integer. used to look at different analysis (maybe xi->17,5 and yj->10 not so good ecc)
gcv <- Xss$gcv  #  the value of the gcv statistic
gcv
par(mfrow=c(2,2),mar=c(6,5,2,1),mex=0.6, mgp=c(2.2,0.7,0),pty="m", font.main=1,font.lab=1, font.axis=1,cex.lab=1.3,cex.axis=1)
plot(abscissa,Xobs0,xlab="t",ylab="observed data")
points(abscissa,Xss0 ,type="l",col="blue",lwd=2)
plot(abscissa[2:(NT-1)],rappincX1,xlab="t",ylab="first differences x",type="l")
points(abscissa,Xss1 ,type="l",col="blue",lwd=2)
plot(abscissa[2:(NT-1)],rappincX2,xlab="t",ylab="second differences x",type="l")
points(abscissa,Xss2 ,type="l",col="blue",lwd=2)
plot(basis)
par(mfrow=c(2,2),mar=c(6,5,2,1),mex=0.6, mgp=c(2.2,0.7,0),pty="m", font.main=1,font.lab=1, font.axis=1,cex.lab=1.3,cex.axis=1)
plot(abscissa,Xobs0,xlab="t",ylab="observed data")
points(abscissa,Xss0 ,type="l",col="blue",lwd=2)
dim(Xobs0)
nbasis <- 30 # number of basis
# Create the basis
#FOURIER
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
x11()
plot.fd(data_W.fd.1)
title("08/06 - 14/06 (smoothing)")
abline(v=seq(1,168, by=24), lty=2)
# FPCA
arm=5 #numero armoniche
plot.fd(data_W.fd.1)
pca_W.1 <- pca.fd(data_W.fd.1,nharm=arm,centerfns=TRUE) #build a functional object before run it -> smoothing preprocessing
# scree plot
# pca.fd computes all the 365 eigenvalues, but only the first are non null
plot(pca_W.1$values[1:5],xlab='j',ylab='Eigenvalues')
plot(cumsum(pca_W.1$values)[1:5]/sum(pca_W.1$values),xlab='j',ylab='CPV',ylim=c(0.8,1))
layout(cbind(1,2,3))
plot(pca_W.1$harmonics[1,],col=1,ylab='FPC1')
abline(h=0,lty=2)
plot(pca_W.1$harmonics[2,],col=2,ylab='FPC2')
plot(pca_W.1$harmonics[3,],col=2,ylab='FPC3')
x11()
media <- mean.fd(data_W.fd.1)
par(mfrow=c(3,1))
plot(media,lwd=2,ylim=c(-25,31),ylab='Stops by each our ~ 22/06 - 28/06',main='FPC1')
lines(media+pca_W.1$harmonics[1,]*sqrt(pca_W.1$values[1]), col=3)
lines(media-pca_W.1$harmonics[1,]*sqrt(pca_W.1$values[1]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC1 - 72.5% of variability")
plot(media,lwd=2,ylim=c(-2,17),ylab='Stops by each our ~ 22/06 - 28/06',main='FPC2')
lines(media+pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=3)
lines(media-pca_W.1$harmonics[2,]*sqrt(pca_W.1$values[2]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC2 - 11.8% of variability")
plot(media,lwd=2,ylim=c(-2,17),ylab='Stops by each our ~ 22/06 - 28/06',main='FPC2')
lines(media+pca_W.1$harmonics[3,]*sqrt(pca_W.1$values[3]), col=3)
lines(media-pca_W.1$harmonics[3,]*sqrt(pca_W.1$values[3]), col=2)
abline(v=seq(1,168, by=24), lty=2, lwd=3)
abline(v=seq(1,168, by=6), lty=3)
title("FPC2 - 4.8% of variability")
x11()
matplot(stops,type='l',main = "22/06 - 28/06")
abline(v=seq(1,168, by=24), lty=2)
abscissa<-1:168
Xobs0<-stops
nbasis <- 30 # number of basis
# Create the basis
#FOURIER
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
x11()
plot.fd(data_W.fd.1)
title("08/06 - 14/06 (smoothing)")
abline(v=seq(1,168, by=24), lty=2)
x11()
matplot(stops,type='l',main = "22/06 - 28/06")
abline(v=seq(1,168, by=24), lty=2)
abscissa<-1:168
Xobs0<-stops
nbasis <- 40 # number of basis
# Create the basis
#FOURIER
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
x11()
plot.fd(data_W.fd.1)
title("22/06 - 28/06 (smoothing)")
abline(v=seq(1,168, by=24), lty=2)
x11()
matplot(stops,type='l',main = "22/06 - 28/06")
abline(v=seq(1,168, by=24), lty=2)
abscissa<-1:168
Xobs0<-stops
nbasis <- 50 # number of basis
# Create the basis
#FOURIER
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
x11()
plot.fd(data_W.fd.1)
title("22/06 - 28/06 (smoothing)")
abline(v=seq(1,168, by=24), lty=2)
x11()
matplot(stops,type='l',main = "22/06 - 28/06")
abline(v=seq(1,168, by=24), lty=2)
abscissa<-1:168
Xobs0<-stops
nbasis <- 50 # number of basis
# Create the basis
#FOURIER
basis <- create.bspline.basis(rangeval=c(1,168),nbasis=nbasis, norder=3) # creates a fourier basis
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
x11()
plot.fd(data_W.fd.1)
title("22/06 - 28/06 (smoothing)")
abline(v=seq(1,168, by=24), lty=2)
nbasis <- 80 # number of basis
# Create the basis
#FOURIER
basis <- create.fourier.basis(rangeval=c(1,168),nbasis=nbasis) # creates a fourier basis
time=1:168
data_W.fd.1 <- Data2fd(y = stops,argvals = time,basisobj = basis) #SMOOTHING
x11()
plot.fd(data_W.fd.1)
title("22/06 - 28/06 (smoothing)")
abline(v=seq(1,168, by=24), lty=2)
