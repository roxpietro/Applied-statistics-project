library(mvtnorm)
library(rgl)
library(car)
species.name <- iris[,5]
iris4        <- iris[,1:4]
iris.e <- dist(iris4, method='euclidean')
View(iris4)
iris.e
a=c(1, 2, 5, 7)
dist(a)
dist(a,method='euclidean')
# simulated data
n <- 100
library(rgl)
library(plotrix)
library(mvtnorm)
library(car)
library(mvnormtest)
library(MASS)
library(class)
library(e1071)
library (ISLR)
library(glmnet)
library(leaps)
library(tree)
load("C:/Users/roxpi/Desktop/R_directory/applied stat/lab5/mcshapiro.test.RData")
set.seed(1)
x <- matrix(rnorm(n*2), ncol=2)
x[1:(n/2),1] <- x[1:(n/2),1]+2
x[1:(n/2),2] <- x[1:(n/2),2]-2
x11()
plot(x,pch=20,cex=2,xlab='x1',ylab='x2')
k <- 2
cluster <- sample(1:2, n, replace=TRUE)
iter.max <- 3
colplot <- c('royalblue','red')
colpoints <- c('blue4','red4')
x11()
par(mfrow = c(iter.max,3))
for(i in 1:iter.max)
{
C <- NULL
for(l in 1:k)
C <- rbind(C, colMeans(x[cluster == l,]))
plot(x, col = colplot[cluster],pch=19)
line <- readline()
points(C, col = colpoints, pch = 4, cex = 2, lwd = 2)
line <- readline()
plot(x, col = 'grey',pch=19)
points(C, col = colpoints, pch = 4, cex = 2, lwd = 2)
line <- readline()
QC <- rbind(C, x)
Dist <- as.matrix(dist(QC, method = 'euclidean'))[(k+1):(k+n),1:k]
for(j in 1:n)
cluster[j] <- which.min(Dist[j,])
plot(x, col = colplot[cluster],pch=19)
points(C, col = colpoints, pch = 4, cex = 2, lwd = 2)
line <- readline()
}
Sys.which("make")
setwd("~/")
Sys.which("make")
Sys.which("make")
## CLUSTERING
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/CLASSIFICAZIONE/Brands/lomba")
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
#rimuovo i cbg che non sono fast food o coffee
index = which(top_category != "Coffee" & top_category != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
attach(new_dataset)
## CREAZIONE FEATURES --> usare max 2 o 3 per avere un plot in 2 o 3 dimensioni
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
sum_breakfast,
raw_stop_counts/raw_device_counts
)
x11()
plot(sum_breakfast - sum_dinner, sum_lunch)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='euclidean')
x.ew <- hclust(x.e, method='ward.D2')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category[-index]
top_category_new <- top_category_new[-lev]
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
View(new_dataset)
## CLUSTERING
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/CLASSIFICAZIONE/Brands/lomba")
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
#rimuovo i cbg che non sono fast food o coffee
index = which(top_category != "Coffee" & top_category != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
attach(new_dataset)
## CREAZIONE FEATURES --> usare max 2 o 3 per avere un plot in 2 o 3 dimensioni
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
sum_work_hours,
raw_stop_counts/raw_device_counts
)
x11()
plot(sum_breakfast - sum_dinner, sum_lunch)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='euclidean')
x.ew <- hclust(x.e, method='ward.D2')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category[-index]
top_category_new <- top_category_new[-lev]
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
N = 100
#rimuovo i cbg che non sono fast food o coffee
top_category_n = top_category[N]
index = which(top_category_n != "Coffee" & top_category_n != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
new = new_dataset[N,]
attach(new)
detach(new)
detach(new)
detach(new_dataset)
detach(new_dataset)
detach(new_dataset)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
N = 100
#rimuovo i cbg che non sono fast food o coffee
top_category_n = top_category[1:N]
index = which(top_category_n != "Coffee" & top_category_n != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
new = new_dataset[1:N,]
new = new_dataset[1:N-length(index),]
length(index)
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
N = 100
#rimuovo i cbg che non sono fast food o coffee
top_category_n = top_category[1:N]
index = which(top_category_n != "Coffee" & top_category_n != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
new = new_dataset[1:N-length(index),]  #ATTENZIONE BISOGNA INSERIRE MANUALMENTE ANCHE I LEV A SECONDA DI N
N-length(index)
new = new_dataset[1:(N-length(index)),]  #ATTENZIONE BISOGNA INSERIRE MANUALMENTE ANCHE I LEV A SECONDA DI N
attach(new)
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
sum_work_hours,
raw_stop_counts/raw_device_counts
)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='euclidean')
x.ew <- hclust(x.e, method='ward.D2')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category_n[-index]
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
