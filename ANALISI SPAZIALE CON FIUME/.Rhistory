k <- 2
cluster <- sample(1:2, n, replace=TRUE)
iter.max <- 3
colplot <- c('royalblue','red')
colpoints <- c('blue4','red4')
x11()
par(mfrow = c(iter.max,3))
for(i in 1:iter.max)
{
C <- NULL
for(l in 1:k)
C <- rbind(C, colMeans(x[cluster == l,]))
plot(x, col = colplot[cluster],pch=19)
line <- readline()
points(C, col = colpoints, pch = 4, cex = 2, lwd = 2)
line <- readline()
plot(x, col = 'grey',pch=19)
points(C, col = colpoints, pch = 4, cex = 2, lwd = 2)
line <- readline()
QC <- rbind(C, x)
Dist <- as.matrix(dist(QC, method = 'euclidean'))[(k+1):(k+n),1:k]
for(j in 1:n)
cluster[j] <- which.min(Dist[j,])
plot(x, col = colplot[cluster],pch=19)
points(C, col = colpoints, pch = 4, cex = 2, lwd = 2)
line <- readline()
}
Sys.which("make")
setwd("~/")
Sys.which("make")
Sys.which("make")
## CLUSTERING
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/CLASSIFICAZIONE/Brands/lomba")
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
#rimuovo i cbg che non sono fast food o coffee
index = which(top_category != "Coffee" & top_category != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
attach(new_dataset)
## CREAZIONE FEATURES --> usare max 2 o 3 per avere un plot in 2 o 3 dimensioni
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
sum_work_hours,
raw_stop_counts/raw_device_counts
)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='euclidean')
x.ew <- hclust(x.e, method='ward.D2')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category[-index]
top_category_new <- top_category_new[-lev] #DA FARE SOLO SE HO TOLTO I LEVERAGES ANCHE PRIMA
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
View(new_dataset)
dataset_pca = data.frame(raw_stop_counts, raw_device_counts, distance_from_home, sum_stops_by_day, sum_afternoon,sum_breakfast, sum_dinner, sum_lunch, sum_night, sum_device_daytime)
pca <- princomp(dataset_pca, scores=T)
pca
summary(pca)
load <- pca$loadings
load
load.tour[,1:8]
load[,1:8]
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
load[,1],
load[,2]
)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='euclidean')
x.ew <- hclust(x.e, method='ward.D2')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category[-index]
top_category_new <- top_category_new[-lev] #DA FARE SOLO SE HO TOLTO I LEVERAGES ANCHE PRIMA
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
## CLUSTERING
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/CLASSIFICAZIONE/Brands/lomba")
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
#rimuovo i cbg che non sono fast food o coffee
index = which(top_category != "Coffee" & top_category != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
attach(new_dataset)
dataset_pca = data.frame(raw_stop_counts, raw_device_counts, distance_from_home, sum_stops_by_day, sum_afternoon,sum_breakfast, sum_dinner, sum_lunch, sum_night, sum_device_daytime)
pca <- princomp(dataset_pca, scores=T)
pca
summary(pca)
load <- pca$loadings
load
load[,1:8]
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
load[,1],
load[,2]
)
scores <- pca$scores
scores
## CLUSTERING
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/CLASSIFICAZIONE/Brands/lomba")
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
#rimuovo i cbg che non sono fast food o coffee
index = which(top_category != "Coffee" & top_category != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
attach(new_dataset)
## CREAZIONE FEATURES --> usare max 2 o 3 per avere un plot in 2 o 3 dimensioni
# proviamo a usare la pca. devo crearmi un nuovo dataset con solo le variabili che volgio utilizzare.
dataset_pca = data.frame(raw_stop_counts, raw_device_counts, distance_from_home, sum_stops_by_day, sum_afternoon,sum_breakfast, sum_dinner, sum_lunch, sum_night, sum_device_daytime)
pca <- princomp(dataset_pca, scores=T)
pca
summary(pca)
load <- pca$loadings
load
load[,1:8]
scores <- pca$scores
scores
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
scores[,1],
scores[,2]
)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='euclidean')
x.ew <- hclust(x.e, method='ward.D2')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category[-index]
top_category_new <- top_category_new[-lev] #DA FARE SOLO SE HO TOLTO I LEVERAGES ANCHE PRIMA
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
## CLUSTERING
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/CLASSIFICAZIONE/Brands/lomba")
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
#rimuovo i cbg che non sono fast food o coffee
index = which(top_category != "Coffee" & top_category != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
attach(new_dataset)
## CREAZIONE FEATURES --> usare max 2 o 3 per avere un plot in 2 o 3 dimensioni
# proviamo a usare la pca. devo crearmi un nuovo dataset con solo le variabili che volgio utilizzare.
dataset_pca = data.frame(raw_stop_counts, raw_device_counts, distance_from_home, sum_stops_by_day, sum_afternoon,sum_breakfast, sum_dinner, sum_lunch, sum_night, sum_device_daytime)
pca <- princomp(dataset_pca, scores=T)
pca
summary(pca)
load <- pca$loadings
load
load[,1:8]
scores <- pca$scores
scores
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
scores[,1],
scores[,2]
)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='euclidean')
x.ew <- hclust(x.e, method='avarage')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category[-index]
top_category_new <- top_category_new[-lev] #DA FARE SOLO SE HO TOLTO I LEVERAGES ANCHE PRIMA
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
## CLUSTERING
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/CLASSIFICAZIONE/Brands/lomba")
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
#rimuovo i cbg che non sono fast food o coffee
index = which(top_category != "Coffee" & top_category != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
attach(new_dataset)
## CREAZIONE FEATURES --> usare max 2 o 3 per avere un plot in 2 o 3 dimensioni
# proviamo a usare la pca. devo crearmi un nuovo dataset con solo le variabili che volgio utilizzare.
dataset_pca = data.frame(raw_stop_counts, raw_device_counts, distance_from_home, sum_stops_by_day, sum_afternoon,sum_breakfast, sum_dinner, sum_lunch, sum_night, sum_device_daytime)
pca <- princomp(dataset_pca, scores=T)
pca
summary(pca)
load <- pca$loadings
load
load[,1:8]
scores <- pca$scores
scores
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
scores[,1],
scores[,2]
)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='euclidean')
x.ew <- hclust(x.e, method='average')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category[-index]
top_category_new <- top_category_new[-lev] #DA FARE SOLO SE HO TOLTO I LEVERAGES ANCHE PRIMA
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
## CLUSTERING
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/CLASSIFICAZIONE/Brands/lomba")
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
#rimuovo i cbg che non sono fast food o coffee
index = which(top_category != "Coffee" & top_category != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
attach(new_dataset)
## CREAZIONE FEATURES --> usare max 2 o 3 per avere un plot in 2 o 3 dimensioni
# proviamo a usare la pca. devo crearmi un nuovo dataset con solo le variabili che volgio utilizzare.
dataset_pca = data.frame(raw_stop_counts, raw_device_counts, distance_from_home, sum_stops_by_day, sum_afternoon,sum_breakfast, sum_dinner, sum_lunch, sum_night, sum_device_daytime)
pca <- princomp(dataset_pca, scores=T)
pca
summary(pca)
load <- pca$loadings
load
load[,1:8]
scores <- pca$scores
scores
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
scores[,1],
scores[,2]
)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='manhattan')
x.ew <- hclust(x.e, method='average')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category[-index]
top_category_new <- top_category_new[-lev] #DA FARE SOLO SE HO TOLTO I LEVERAGES ANCHE PRIMA
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
## CLUSTERING
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/CLASSIFICAZIONE/Brands/lomba")
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
#rimuovo i cbg che non sono fast food o coffee
index = which(top_category != "Coffee" & top_category != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
attach(new_dataset)
## CREAZIONE FEATURES --> usare max 2 o 3 per avere un plot in 2 o 3 dimensioni
# proviamo a usare la pca. devo crearmi un nuovo dataset con solo le variabili che volgio utilizzare.
dataset_pca = data.frame(raw_stop_counts, raw_device_counts, distance_from_home, sum_stops_by_day, sum_afternoon,sum_breakfast, sum_dinner, sum_lunch, sum_night, sum_device_daytime)
pca <- princomp(dataset_pca, scores=T)
pca
summary(pca)
load <- pca$loadings
load
load[,1:8]
scores <- pca$scores
scores
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
scores[,1],
scores[,2]
)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='manhattan')
x.ew <- hclust(x.e, method='single')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category[-index]
top_category_new <- top_category_new[-lev] #DA FARE SOLO SE HO TOLTO I LEVERAGES ANCHE PRIMA
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
## CLUSTERING
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/CLASSIFICAZIONE/Brands/lomba")
#libraries
library(rgl)
library(mvtnorm)
## DATASET
load("NYC_no_river.RData")
load("top_category.Rdata")
#rimuovo gli outliers/leverages  (righe 213,247,712,918)
lev = c(213,247,712,918)
new_dataset_withoutlier <- New_York_County_no_river[-lev,]
rm(New_York_County_no_river)
#rimuovo i cbg che non sono fast food o coffee
index = which(top_category != "Coffee" & top_category != "Fast Food")
new_dataset <- new_dataset_withoutlier[-index,]
rm(new_dataset_withoutlier)
attach(new_dataset)
## CREAZIONE FEATURES --> usare max 2 o 3 per avere un plot in 2 o 3 dimensioni
# proviamo a usare la pca. devo crearmi un nuovo dataset con solo le variabili che volgio utilizzare.
dataset_pca = data.frame(raw_stop_counts, raw_device_counts, distance_from_home, sum_stops_by_day, sum_afternoon,sum_breakfast, sum_dinner, sum_lunch, sum_night, sum_device_daytime)
pca <- princomp(dataset_pca, scores=T)
pca
summary(pca)
load <- pca$loadings
load
load[,1:8]
scores <- pca$scores
scores
#provo il caso più generale con sum_breakfast, sum_lunch e sum_dinner
tre_sum <- data.frame(
scores[,1],
scores[,2]
)
## HIERACHICAL CLUSTERING
x.e <- dist(tre_sum, method='manhattan')
x.ew <- hclust(x.e, method='ward.D2')
x11()
plot(x.ew, main='euclidean-ward', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
rect.hclust(x.ew, k=2)
cluster.ew <- cutree(x.ew, k=2)
top_category_new <- top_category[-index]
top_category_new <- top_category_new[-lev] #DA FARE SOLO SE HO TOLTO I LEVERAGES ANCHE PRIMA
coffee_index <- which(top_category_new == 'Coffee')
fast_food_index <- which(top_category_new == 'Fast Food')
x11()
#plot(x_new, col=ifelse(cluster.ew==1,'red','blue'), pch=19)
plot(tre_sum[coffee_index,], col = 'red')
points(tre_sum[fast_food_index,], col = 'blue')
View(new_dataset)
setwd("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/ANALISI SPAZIALE CON FIUME")
library(geosphere)
library(sf)
library(sp)           ## Data management
library(lattice)      ## Data management
library(geoR)         ## Geostatistics
library(gstat)        ## Geostatistics
library(ggplot2)
library(raster)
library(rgdal)
New_York_County_no_river=New_York_County_no_river[order(New_York_County_no_river$area),]
CBG_ny_no_river=CBG_ny_no_river[order(CBG_ny_no_river$CensusBlockGroup),]
load("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/DATASET/NYC_no_river.RData")
load("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/DATASET/CBG_NY_no_river.RData")
load("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/DATASET/River_Dataset.RData")
New_York_County_no_river=New_York_County_no_river[order(New_York_County_no_river$area),]
CBG_ny_no_river=CBG_ny_no_river[order(CBG_ny_no_river$CensusBlockGroup),]
attach(New_York_County_no_river)
#coordinate in utm
centroids_NY <- st_centroid(CBG_ny_no_river$geometry, of_largest_polygon = FALSE)
coord_NY <- as.numeric(unlist(centroids_NY))
coord.x_long <- coord_NY[seq(1,length(coord_NY),by=2)]
coord.y_lat <- coord_NY[seq(2,length(coord_NY),by=2)]
coord<-SpatialPoints(cbind(coord.x_long,coord.y_lat),proj4string=CRS("+proj=longlat"))
coord.UTM.NY <- spTransform(coord, CRS("+proj=utm +zone=18 +datum=WGS84"))
coord.x <- coord.UTM.NY@coords[,1]
coord.y <- coord.UTM.NY@coords[,2]
##focus su DISTANCE_FROM_HOME
rem <- which(distance_from_home > 20000) #[36] > 125000, [175]  > 50000, [1,9] >30000 , [92] >20000
CBG_ny_no_river$CensusBlockGroup[rem]
#dati molto alti che non fanno vedere pattern nel grafico -> da capire se togliere o no
min(distance_from_home)
max(distance_from_home)
# data_spatial <-data.frame(coord.x,coord.y, z)
# coordinates(data_spatial)<-c('coord.x', 'coord.y')
x11()
distance__from_home <- distance_from_home[-rem]
#png(file = "glop distance from home.png")
ggplot() +
geom_sf(data = CBG_ny_no_river$geometry[-rem], aes(fill=distance__from_home))+scale_fill_gradient(low="lightyellow", high="red") +
geom_sf(data = CBG_ny_no_river$geometry[rem,], fill="black")+
geom_sf(data = CBG_ny_no_river$geometry[which(CBG_ny_no_river$TractCode=="011300"),], fill="yellow") +
geom_sf(data = CBG_RIVER$geometry, fill="lightblue")
dev.off()
x11()
distance__from_home <- distance_from_home[-rem]
#png(file = "glop distance from home.png")
ggplot() +
geom_sf(data = CBG_ny_no_river$geometry[-rem], aes(fill=distance__from_home))+scale_fill_gradient(low="lightyellow", high="red") +
geom_sf(data = CBG_ny_no_river$geometry[rem,], fill="black")+
geom_sf(data = CBG_ny_no_river$geometry[which(CBG_ny_no_river$TractCode=="011300"),], fill="yellow") +
geom_sf(data = CBG_RIVER$geometry, fill="lightblue")
detach(New_York_County_no_river)
detach(New_York_County_no_river)
library(geosphere)
library(sf)
library(sp)           ## Data management
library(lattice)      ## Data management
library(geoR)         ## Geostatistics
library(gstat)        ## Geostatistics
library(ggplot2)
library(raster)
library(rgdal)
load("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/DATASET/NYC_no_river.RData")
load("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/DATASET/CBG_NY_no_river.RData")
load("C:/Users/roxpi/Desktop/R_directory/applied stat/Applied-statistics-project/DATASET/River_Dataset.RData")
New_York_County_no_river=New_York_County_no_river[order(New_York_County_no_river$area),]
CBG_ny_no_river=CBG_ny_no_river[order(CBG_ny_no_river$CensusBlockGroup),]
attach(New_York_County_no_river)
#coordinate in utm
centroids_NY <- st_centroid(CBG_ny_no_river$geometry, of_largest_polygon = FALSE)
coord_NY <- as.numeric(unlist(centroids_NY))
coord.x_long <- coord_NY[seq(1,length(coord_NY),by=2)]
coord.y_lat <- coord_NY[seq(2,length(coord_NY),by=2)]
coord<-SpatialPoints(cbind(coord.x_long,coord.y_lat),proj4string=CRS("+proj=longlat"))
coord.UTM.NY <- spTransform(coord, CRS("+proj=utm +zone=18 +datum=WGS84"))
coord.x <- coord.UTM.NY@coords[,1]
coord.y <- coord.UTM.NY@coords[,2]
##focus su DISTANCE_FROM_HOME
rem <- which(distance_from_home > 20000) #[36] > 125000, [175]  > 50000, [1,9] >30000 , [92] >20000
CBG_ny_no_river$CensusBlockGroup[rem]
#dati molto alti che non fanno vedere pattern nel grafico -> da capire se togliere o no
min(distance_from_home)
max(distance_from_home)
# data_spatial <-data.frame(coord.x,coord.y, z)
# coordinates(data_spatial)<-c('coord.x', 'coord.y')
x11()
distance__from_home <- distance_from_home[-rem]
#png(file = "glop distance from home.png")
ggplot() +
geom_sf(data = CBG_ny_no_river$geometry[-rem], aes(fill=distance__from_home))+scale_fill_gradient(low="lightyellow", high="red") +
geom_sf(data = CBG_ny_no_river$geometry[rem,], fill="black")+
geom_sf(data = CBG_ny_no_river$geometry[which(CBG_ny_no_river$TractCode=="011300"),], fill="yellow") +
geom_sf(data = CBG_RIVER$geometry, fill="lightblue")
