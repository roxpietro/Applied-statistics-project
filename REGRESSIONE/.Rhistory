##data
library(car)
load("New York County.RData")
load("C:/Users/franc/Desktop/PoliMI/Anno Accademico 2020-2021/Applied Statistics/Prog/Applied-statistics-project/DATASET/Data frame county/New York County.RData")
load("C:/Users/franc/Desktop/PoliMI/Anno Accademico 2020-2021/Applied Statistics/Prog/Applied-statistics-project/DATASET/Data frame county/New York County.RData"))
load("C:/Users/franc/Desktop/PoliMI/Anno Accademico 2020-2021/Applied Statistics/Prog/Applied-statistics-project/DATASET/Data frame county/New York County.RData")
NY_county <- sub_patt
rm(sub_patt)
attach(NY_county)
LM_1=data.frame(median_dwell,raw_stop_counts,raw_device_counts,distance_from_home,distance_from_primary_daytime_location)
detach(NY_county)
attach(LM_1)
## vediamo come sono distribuiti i dati (male)
pairs(LM_1)
# Load dataset and build dataframe
load("C:/Users/franc/Desktop/PoliMI/Anno Accademico 2020-2021/Applied Statistics/Prog/Applied-statistics-project/DATASET/Data frame county/New York County.RData")
NY_county <- sub_patt
rm(sub_patt)
attach(NY_county)
LM_1=data.frame(median_dwell,raw_stop_counts,raw_device_counts,distance_from_home,distance_from_primary_daytime_location)
detach(NY_county)
attach(LM_1)
# vediamo come sono distribuiti i dati
pairs(LM_1) # fanno sboccare
######################### ESEMPI DI REGRESSIONE ###################################
# facciamo un linear model solo con le prime due variabili (risultati molto bassi)
mod=lm(formula = median_dwell ~ raw_stop_counts + raw_device_counts)
summary(mod)
## Dobbiamo trovare una trasformazione che renda il modello più lineare
# 1. decidiamo di fare il boxcox del modello (univariate)
#---------------------------------------------------------------------------------------
b=boxcox(mod)
best_lambda_ind=which.max(b$y)
lambda=b$x[best_lambda_ind]
box_cox <- function(x,lambda)
{
if(lambda!=0)
return((x^lambda-1)/lambda)
return(log(x))
}
new_raw_stop_counts = box_cox(raw_stop_counts,lambda)
new_raw_device_counts = box_cox(raw_device_counts,lambda)
new_median_dwell = box_cox(median_dwell,lambda)
mod_boxcox=lm(formula = new_median_dwell ~ new_raw_stop_counts + new_raw_device_counts)
summary(mod_boxcox) #0.02
b=boxCox(mod)
best_lambda_ind=which.max(b$y)
lambda=b$x[best_lambda_ind]
box_cox <- function(x,lambda)
{
if(lambda!=0)
return((x^lambda-1)/lambda)
return(log(x))
}
new_raw_stop_counts = box_cox(raw_stop_counts,lambda)
new_raw_device_counts = box_cox(raw_device_counts,lambda)
new_median_dwell = box_cox(median_dwell,lambda)
mod_boxcox=lm(formula = new_median_dwell ~ new_raw_stop_counts + new_raw_device_counts)
summary(mod_boxcox) #0.02
lambda.raw_stop <- powerTransform(raw_stop_counts)
lambda.raw_device <- powerTransform(raw_device_counts)
lambda.median <- powerTransform(median_dwell)
bc.raw_stop <- bcPower(raw_stop_counts, lambda.raw_stop$lambda)
bc.raw_device <- bcPower(raw_device_counts, lambda.raw_device$lambda)
bc.median <- bcPower(median_dwell, lambda.median$lambda)
mod_power=lm(formula = bc.median ~ bc.raw_stop + bc.raw_device)
summary(mod_power)
mod_power=lm(formula = median_dwell ~ bc.raw_stop + bc.raw_device)
summary(mod_power) #0.29
lambda_multivariate <- powerTransform(cbind(raw_stop_counts, raw_device_counts,median_dwell))
BC.stop <- bcPower(raw_stop_counts, lambda_multivariate$lambda[1])
BC.device <- bcPower(raw_device_counts, lambda_multivariate$lambda[2])
BC.median <- bcPower(median_dwell, lambda_multivariate$lambda[3])
mod_multivariate=lm(formula = BC.median ~ BC.stop + BC.device)
summary(mod_multivariate)
lambda_multivariate
BC.stop <- bcPower(raw_stop_counts, 0)
BC.device <- bcPower(raw_device_counts, 0)
BC.median <- bcPower(median_dwell, lambda_multivariate$lambda[3])
mod_multivariate=lm(formula = BC.median ~ BC.stop + BC.device)
summary(mod_multivariate) #0.68
x11()
plot(BC.stop, BC.median)
# #questo ultimo metodo è quello che mi da un R^2 maggiore
# da capire il significato di coeff positivi e negativi
#------------------------------------------------------------------------------------------------------------
#4. Provo con l'ultimo modello aggiungendo features
#------------------------------------------------------------------------------------------------------------
lambda_multivariate <- powerTransform(cbind(raw_stop_counts, raw_device_counts,distance_from_home,distance_from_primary_daytime_location,median_dwell))
lambda_multivariate
BC.stop <- bcPower(raw_stop_counts, 0)
BC.device <- bcPower(raw_device_counts, 0)
BC.home <- bcPower(distance_from_home, lambda_multivariate$lambda[3])
BC.primary <- bcPower(distance_from_primary_daytime_location, lambda_multivariate$lambda[4])
BC.median <- bcPower(median_dwell, lambda_multivariate$lambda[5])
mod_multivariate_complete=lm(formula = BC.median ~ BC.stop + BC.device + BC.home)
summary(mod_multivariate_complete) #0.62
mod_multivariate_complete=lm(formula = BC.median ~ BC.stop + BC.device + BC.home + BC.primary)
summary(mod_multivariate_complete) #0.69
# Vediamo che le ultime due features non sembrano essere significative. dal pairs avevamo visto che sono correlate.
# Risolviamo il problema della collinearità
vif(mod_multivariate_complete)
vif(mod_multivariate)
LM.PCA <- princomp(cbind(BC.stop,BC.device,BC.home,BC.primary), scores=TRUE)
summary(LM.PCA)
LM.PCA$load
cbind(BC.stop,BC.device,BC.home,BC.primary)
is.na(LM_1)
which(is.na(LM_1))
View(LM_1)
which(is.na(BC.stop))
which(is.na(BC.device))
which(is.na(BC.home))
which(is.na(BC.primary))
a=LM_1[-92,]
LM_1=data.frame(median_dwell,raw_stop_counts,raw_device_counts,distance_from_home,distance_from_primary_daytime_location)
LM_1<-LM_1[-92,]
detach(NY_county)
attach(LM_1)
# vediamo come sono distribuiti i dati
pairs(LM_1) # fanno sboccare
######################### ESEMPI DI REGRESSIONE ###################################
# facciamo un linear model solo con le prime due variabili (risultati molto bassi)
mod=lm(formula = median_dwell ~ raw_stop_counts + raw_device_counts)
summary(mod)
## Dobbiamo trovare una trasformazione che renda il modello più lineare
# 1. decidiamo di fare il boxcox del modello (univariate)
#---------------------------------------------------------------------------------------
b=boxCox(mod)
best_lambda_ind=which.max(b$y)
lambda=b$x[best_lambda_ind]
box_cox <- function(x,lambda)
{
if(lambda!=0)
return((x^lambda-1)/lambda)
return(log(x))
}
new_raw_stop_counts = box_cox(raw_stop_counts,lambda)
new_raw_device_counts = box_cox(raw_device_counts,lambda)
new_median_dwell = box_cox(median_dwell,lambda)
mod_boxcox=lm(formula = new_median_dwell ~ new_raw_stop_counts + new_raw_device_counts)
summary(mod_boxcox) #0.38
#---------------------------------------------------------------------------------------------------------
#2. Proviamo a vedere se cambia qualcosa con il Powertransformation di ogni variabile (univariate)
#---------------------------------------------------------------------------------------------------------
lambda.raw_stop <- powerTransform(raw_stop_counts)
lambda.raw_device <- powerTransform(raw_device_counts)
lambda.median <- powerTransform(median_dwell)
bc.raw_stop <- bcPower(raw_stop_counts, lambda.raw_stop$lambda)
bc.raw_device <- bcPower(raw_device_counts, lambda.raw_device$lambda)
bc.median <- bcPower(median_dwell, lambda.median$lambda)
mod_power=lm(formula = bc.median ~ bc.raw_stop + bc.raw_device)
summary(mod_power) #0.475
mod_power=lm(formula = median_dwell ~ bc.raw_stop + bc.raw_device)
summary(mod_power) #0.496
mod_power=lm(formula = bc.median ~ raw_stop_counts + raw_device_counts)
summary(mod_power) #0.03
#------------------------------------------------------------------------------------------------------------
#3. Multivariate case
#------------------------------------------------------------------------------------------------------------
lambda_multivariate <- powerTransform(cbind(raw_stop_counts, raw_device_counts,median_dwell))
lambda_multivariate
BC.stop <- bcPower(raw_stop_counts, 0)
BC.device <- bcPower(raw_device_counts, 0)
BC.median <- bcPower(median_dwell, lambda_multivariate$lambda[3])
mod_multivariate=lm(formula = BC.median ~ BC.stop + BC.device)
summary(mod_multivariate) #0.69
vif(mod_multivariate) # non c'è collinearità
# #questo ultimo metodo è quello che mi da un R^2 maggiore
# da capire il significato di coeff positivi e negativi
#------------------------------------------------------------------------------------------------------------
#4. Provo con l'ultimo modello aggiungendo features
#------------------------------------------------------------------------------------------------------------
lambda_multivariate <- powerTransform(cbind(raw_stop_counts, raw_device_counts,distance_from_home,distance_from_primary_daytime_location,median_dwell))
lambda_multivariate
BC.stop <- bcPower(raw_stop_counts, 0)
BC.device <- bcPower(raw_device_counts, 0)
BC.home <- bcPower(distance_from_home, lambda_multivariate$lambda[3])
BC.primary <- bcPower(distance_from_primary_daytime_location, lambda_multivariate$lambda[4])
BC.median <- bcPower(median_dwell, lambda_multivariate$lambda[5])
mod_multivariate_complete=lm(formula = BC.median ~ BC.stop + BC.device + BC.home + BC.primary)
summary(mod_multivariate_complete) #0.69
vif(mod_multivariate_complete) # infatti abbiamo vif = 36, da 10 in poi sono collineari
#------------------------------------------------------------------------------------------------------------
# 1 approccio: PCA
#------------------------------------------------------------------------------------------------------------
LM.PCA <- princomp(cbind(BC.stop,BC.device,BC.home,BC.primary), scores=TRUE)
summary(LM.PCA)
LM.PCA$load
PC1 <- LM.PCA$scores[,1]
# Now we estimate the model by inserting the PCs instead of the
# original regressors
# Model: y = b0 + b1*PC1+ b2*PC2 + eps, eps~N(0,sigma^2)
lm.pca1 <- lm(BC.median ~ PC1)
summary(lm.pca1)
PC2 <- LM.PCA$scores[,2]
# Now we estimate the model by inserting the PCs instead of the
# original regressors
# Model: y = b0 + b1*PC1+ b2*PC2 + eps, eps~N(0,sigma^2)
lm.pca1 <- lm(BC.median ~ PC1 + PC2)
summary(lm.pca1)
PC1 <- LM.PCA$scores[,1]
PC2 <- LM.PCA$scores[,2]
PC3 <- LM.PCA$scores[,3]
PC4 <- LM.PCA$scores[,4]
# first component explains all data more or less
# scores are used as new betas
# Now we estimate the model by inserting the PCs instead of the
# original regressors
# Model: y = b0 + b1*PC1+ b2*PC2 + eps, eps~N(0,sigma^2)
lm.pca1 <- lm(BC.median ~ PC1 + PC2+ PC3 + PC4)
summary(lm.pca1)
lm.pca1 <- lm(BC.median ~ PC1 + PC2+ PC3)
summary(lm.pca1)
lm.pca1 <- lm(BC.median ~ PC1 + PC2+ PC4)
summary(lm.pca1)
# Model: y = b0 + b1*PC1+ b2*PC2 + eps, eps~N(0,sigma^2)
lm.pca1 <- lm(BC.median ~ PC4)
summary(lm.pca1)
LM.PCA <- princomp(cbind(BC.stop,BC.device,BC.home,BC.primary), scores=TRUE)
LM.PCA <- princomp(cbind(BC.stop,BC.device,BC.home,BC.primary), scores=TRUE)
summary(LM.PCA)
LM.PCA$load
